{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D0eIkoQOhwi",
        "outputId": "5450c4a5-e73d-48b2-f072-c0e9b26393bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.9.24)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "PbjDVm3yO3s8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee9e2a8-0041-440f-99d2-50735d4fa680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "rnO9opKkPAKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a213ccf2-a6e9-41c4-c798-c4226ff48292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "POFPsvhaPLFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a484a72-f620-4e18-edb0-74b5eb42c2e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c nlp-getting-started"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0fLHqkmQDDP",
        "outputId": "1d03e832-d812-4d01-ce93-af244aa05d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/kaggle/api/kaggle_api_extended.py\", line 166, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/nlp-getting-started.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN5USbcuQLzE",
        "outputId": "642a76a9-e4ad-49f4-f41f-0af15007f6b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/nlp-getting-started.zip, /content/nlp-getting-started.zip.zip or /content/nlp-getting-started.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.initializers import Constant\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import (LSTM, \n",
        "                          Embedding, \n",
        "                          BatchNormalization,\n",
        "                          Dense, \n",
        "                          TimeDistributed, \n",
        "                          Dropout, \n",
        "                          Bidirectional,\n",
        "                          Flatten, \n",
        "                          GlobalMaxPool1D)\n",
        "from keras.layers import Embedding\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import (\n",
        "    precision_score, \n",
        "    recall_score, \n",
        "    f1_score, \n",
        "    classification_report,\n",
        "    accuracy_score\n",
        ")\n"
      ],
      "metadata": {
        "id": "VKoJFNreQhoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2887be83-0596-452f-bab1-788ede622384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = pd.read_csv('train.csv')\n",
        "data_test = pd.read_csv('test.csv')\n",
        "data_train"
      ],
      "metadata": {
        "id": "UQmFiTpn-NyO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "fe4b6de6-b095-481f-8506-45728d74b036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id keyword location  \\\n",
              "0         1     NaN      NaN   \n",
              "1         4     NaN      NaN   \n",
              "2         5     NaN      NaN   \n",
              "3         6     NaN      NaN   \n",
              "4         7     NaN      NaN   \n",
              "...     ...     ...      ...   \n",
              "7608  10869     NaN      NaN   \n",
              "7609  10870     NaN      NaN   \n",
              "7610  10871     NaN      NaN   \n",
              "7611  10872     NaN      NaN   \n",
              "7612  10873     NaN      NaN   \n",
              "\n",
              "                                                   text  target  \n",
              "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
              "1                Forest fire near La Ronge Sask. Canada       1  \n",
              "2     All residents asked to 'shelter in place' are ...       1  \n",
              "3     13,000 people receive #wildfires evacuation or...       1  \n",
              "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
              "...                                                 ...     ...  \n",
              "7608  Two giant cranes holding a bridge collapse int...       1  \n",
              "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
              "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
              "7611  Police investigating after an e-bike collided ...       1  \n",
              "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
              "\n",
              "[7613 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a199979-303c-48f2-b1c3-3fd24514fe8f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7608</th>\n",
              "      <td>10869</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7609</th>\n",
              "      <td>10870</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7610</th>\n",
              "      <td>10871</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7611</th>\n",
              "      <td>10872</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Police investigating after an e-bike collided ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7612</th>\n",
              "      <td>10873</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a199979-303c-48f2-b1c3-3fd24514fe8f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a199979-303c-48f2-b1c3-3fd24514fe8f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a199979-303c-48f2-b1c3-3fd24514fe8f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([data_train,data_test])\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "d2gNDMZU_8D-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1a22671-7a2e-4469-deb0-7bae28cba4f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10876, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess text\n",
        "def clean_text(text):\n",
        "    ''' lowercase, remove square brackets,remove links,remove punctuation\n",
        "    , words containing numbers.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text\n",
        "\n",
        "data_train['text'] = data_train['text'].apply(lambda x: clean_text(x))\n",
        "data_train['text'].head()"
      ],
      "metadata": {
        "id": "7dFLu4yz-jrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b568626-6ff4-47f8-acf5-40c39f9fea98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    our deeds are the reason of this earthquake ma...\n",
              "1                forest fire near la ronge sask canada\n",
              "2    all residents asked to shelter in place are be...\n",
              "3     people receive wildfires evacuation orders in...\n",
              "4    just got sent this photo from ruby alaska as s...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\" \n",
        "                           u\"\\U0001F300-\\U0001F5FF\"\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "df['text']=df['text'].apply(lambda x: remove_emoji(x))"
      ],
      "metadata": {
        "id": "ZFwYrI3sB1pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = data_train.text.values\n",
        "test = data_test.text.values\n",
        "sentiments = data_train.target.values"
      ],
      "metadata": {
        "id": "LM8dbP4aCGHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word Tokenization\n",
        "word_tokenizer = Tokenizer()\n",
        "word_tokenizer.fit_on_texts(tweet)\n",
        "vocab_length = len(word_tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "1-yuS1xtCRI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create merics func\n",
        "def metrics(pred_tag, y_test):\n",
        "    print(\"F1-score: \", f1_score(pred_tag, y_test))\n",
        "    print(\"Precision: \", precision_score(pred_tag, y_test))\n",
        "    print(\"Recall: \", recall_score(pred_tag, y_test))\n",
        "    print(\"Acuracy: \", accuracy_score(pred_tag, y_test))\n",
        "    print(\"-\"*50)\n",
        "    print(classification_report(pred_tag, y_test))\n",
        "def embed(corpus): \n",
        "    return word_tokenizer.texts_to_sequences(corpus)"
      ],
      "metadata": {
        "id": "bFtAnRcDEBHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(history, arr):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
        "    for idx in range(2):\n",
        "        ax[idx].plot(history.history[arr[idx][0]])\n",
        "        ax[idx].plot(history.history[arr[idx][1]])\n",
        "        ax[idx].legend([arr[idx][0], arr[idx][1]],fontsize=18)\n",
        "        ax[idx].set_xlabel('A ',fontsize=16)\n",
        "        ax[idx].set_ylabel('B',fontsize=16)\n",
        "        ax[idx].set_title(arr[idx][0] + ' X ' + arr[idx][1],fontsize=16)"
      ],
      "metadata": {
        "id": "NDwNbVsUEeJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "longest_train = max(tweet, key=lambda sentence: len(word_tokenize(sentence)))\n",
        "length_long_sentence = len(word_tokenize(longest_train))\n",
        "padded_sentences = pad_sequences(embed(tweet), length_long_sentence, padding='post')\n",
        "test_sentences = pad_sequences(\n",
        "    embed(test), \n",
        "    length_long_sentence,\n",
        "    padding='post'\n",
        ")"
      ],
      "metadata": {
        "id": "7eKswamYEGHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Word embedding using Glove\n",
        "embeddings_dictionary = dict()\n",
        "embedding_dim = 100\n",
        "glove_file = open('glove.6B.100d.txt')\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary[word] = vector_dimensions\n",
        "glove_file.close()"
      ],
      "metadata": {
        "id": "H-mbX08uFAPb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "d9e7466d-2b5e-46f5-d5b3-e018d59b7dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-b22061a3e845>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membeddings_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mglove_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'glove.6B.100d.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglove_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'glove.6B.100d.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_length, embedding_dim))\n",
        "for word, index in word_tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "metadata": {
        "id": "Vx8h9rOIGpRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    padded_sentences, \n",
        "    sentiments, \n",
        "    test_size=0.25\n",
        ")"
      ],
      "metadata": {
        "id": "UebyICsWt4YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def BiLSTM():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=embedding_matrix.shape[0], \n",
        "                        output_dim=embedding_matrix.shape[1], \n",
        "                        weights = [embedding_matrix], \n",
        "                        input_length=length_long_sentence))\n",
        "    model.add(Bidirectional(LSTM(length_long_sentence, return_sequences = True, recurrent_dropout=0.2)))\n",
        "    model.add(GlobalMaxPool1D())\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(length_long_sentence, activation = \"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(length_long_sentence, activation = \"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "NZw1KArgt8rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_matrix.shape)"
      ],
      "metadata": {
        "id": "kU07BP6suWvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BiLSTM()\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'model.h5', \n",
        "    monitor = 'val_loss', \n",
        "    verbose = 1, \n",
        "    save_best_only = True\n",
        ")\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor = 'val_loss', \n",
        "    factor = 0.2, \n",
        "    verbose = 1, \n",
        "    patience = 5,                        \n",
        "    min_lr = 0.001\n",
        ")\n",
        "history = model.fit(\n",
        "    X_train, \n",
        "    y_train, \n",
        "    epochs = 8,\n",
        "    batch_size = 32,\n",
        "    validation_data = [X_test, y_test],\n",
        "    verbose = 1,\n",
        "    callbacks = [reduce_lr, checkpoint]\n",
        ")"
      ],
      "metadata": {
        "id": "NEGsthMEubDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(history, [['loss', 'val_loss'],['accuracy', 'val_accuracy']])"
      ],
      "metadata": {
        "id": "Bkme8daqukLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print('Loss:', loss)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "id": "pfj-FKvYvPDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('model.h5')\n",
        "preds = model.predict(X_test)\n",
        "preds = np.round(preds).astype(int)\n",
        "metrics(preds, y_test)"
      ],
      "metadata": {
        "id": "_zKfeds0wWc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit_result = pd.read_csv('/content/sample_submission.csv')\n",
        "preds = model.predict(test_sentences)\n",
        "preds_classes = np.argmax(preds, axis=1)\n",
        "submit_result.target = preds_classes\n",
        "submit_result.to_csv(\"submit_NLP.csv\", index=False)"
      ],
      "metadata": {
        "id": "_Ju6bhRmxMg_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}